{
    "metadata": {
        "language_info": {
            "file_extension": ".py", 
            "name": "python", 
            "mimetype": "text/x-python", 
            "nbconvert_exporter": "python", 
            "version": "2.7.11", 
            "codemirror_mode": {
                "name": "ipython", 
                "version": 2
            }, 
            "pygments_lexer": "ipython2"
        }, 
        "kernelspec": {
            "display_name": "Python 2 with Spark 2.0", 
            "name": "python2-spark20", 
            "language": "python"
        }
    }, 
    "nbformat": 4, 
    "cells": [
        {
            "metadata": {}, 
            "source": "# Load the clean NFL data", 
            "cell_type": "markdown"
        }, 
        {
            "metadata": {
                "collapsed": true
            }, 
            "source": "# The code was removed by DSX for sharing.", 
            "execution_count": 2, 
            "cell_type": "code", 
            "outputs": []
        }, 
        {
            "metadata": {}, 
            "source": "configuration_name = 'os_f02c10e2d3544fe3ae82e368ee5170ef_configs'\nbmos = ibmos2spark.bluemix(sc, credentials, configuration_name)\n\ndf = spark.read\\\n  .format('org.apache.spark.sql.execution.datasources.csv.CSVFileFormat')\\\n  .option('header', 'true').option('inferschema','true')\\\n  .load(bmos.url('HWNFLDemo', 'fixed_rb_filtered.csv'))\ndf.take(2)", 
            "execution_count": 5, 
            "cell_type": "code", 
            "outputs": [
                {
                    "data": {
                        "text/plain": "[Row(_c0=0, name=u'C.Newton', position=u'QB', rushing_yds=43, home=True, opponent=u'NO', stadium_city=u'Charlotte, NC', capacity=u'75,419', surface=u'Voyager Bermuda Grass', roof=u'Open', temp=65, wspd=7),\n Row(_c0=1, name=u'J.Stewart', position=u'RB', rushing_yds=46, home=True, opponent=u'NO', stadium_city=u'Charlotte, NC', capacity=u'75,419', surface=u'Voyager Bermuda Grass', roof=u'Open', temp=65, wspd=7)]"
                    }, 
                    "metadata": {}, 
                    "execution_count": 5, 
                    "output_type": "execute_result"
                }
            ]
        }, 
        {
            "metadata": {}, 
            "source": "df.where(\"stadium_city like '%MN'\").take(5)", 
            "execution_count": 6, 
            "cell_type": "code", 
            "outputs": [
                {
                    "data": {
                        "text/plain": "[Row(_c0=1437, name=u'S.Bradford', position=u'QB', rushing_yds=6, home=True, opponent=u'NYG', stadium_city=u'Minneapolis, MN', capacity=u'66,655', surface=u'UBU Speed Series S5-M Synthetic Turf', roof=u'Fixed', temp=49, wspd=0),\n Row(_c0=1438, name=u'S.Diggs', position=u'WR', rushing_yds=-1, home=True, opponent=u'NYG', stadium_city=u'Minneapolis, MN', capacity=u'66,655', surface=u'UBU Speed Series S5-M Synthetic Turf', roof=u'Fixed', temp=49, wspd=0),\n Row(_c0=1439, name=u'J.McKinnon', position=u'RB', rushing_yds=85, home=True, opponent=u'NYG', stadium_city=u'Minneapolis, MN', capacity=u'66,655', surface=u'UBU Speed Series S5-M Synthetic Turf', roof=u'Fixed', temp=49, wspd=0),\n Row(_c0=1440, name=u'Z.Line', position=u'FB', rushing_yds=6, home=True, opponent=u'NYG', stadium_city=u'Minneapolis, MN', capacity=u'66,655', surface=u'UBU Speed Series S5-M Synthetic Turf', roof=u'Fixed', temp=49, wspd=0),\n Row(_c0=1441, name=u'C.Patterson', position=u'WR', rushing_yds=2, home=True, opponent=u'NYG', stadium_city=u'Minneapolis, MN', capacity=u'66,655', surface=u'UBU Speed Series S5-M Synthetic Turf', roof=u'Fixed', temp=49, wspd=0)]"
                    }, 
                    "metadata": {}, 
                    "execution_count": 6, 
                    "output_type": "execute_result"
                }
            ]
        }, 
        {
            "metadata": {}, 
            "source": "df.count()", 
            "execution_count": 22, 
            "cell_type": "code", 
            "outputs": [
                {
                    "data": {
                        "text/plain": "4391"
                    }, 
                    "metadata": {}, 
                    "execution_count": 22, 
                    "output_type": "execute_result"
                }
            ]
        }, 
        {
            "metadata": {}, 
            "source": "# Remove null rows and rows with values that don't appear enough for training", 
            "cell_type": "markdown"
        }, 
        {
            "metadata": {
                "collapsed": true
            }, 
            "source": "df = df.where(\"not temp is Null\")", 
            "execution_count": 23, 
            "cell_type": "code", 
            "outputs": []
        }, 
        {
            "metadata": {
                "collapsed": true
            }, 
            "source": "df = df.withColumn('ishome', df['home'].cast('integer'))", 
            "execution_count": 24, 
            "cell_type": "code", 
            "outputs": []
        }, 
        {
            "metadata": {
                "collapsed": true
            }, 
            "source": "df.groupBy(\"position\").count().where('count < 10').createOrReplaceTempView(\"lowPosCount\")", 
            "execution_count": 25, 
            "cell_type": "code", 
            "outputs": []
        }, 
        {
            "metadata": {
                "collapsed": true
            }, 
            "source": "df.groupBy(\"name\").count().where('count < 10').createOrReplaceTempView(\"lowNameCount\")", 
            "execution_count": 26, 
            "cell_type": "code", 
            "outputs": []
        }, 
        {
            "metadata": {
                "collapsed": true
            }, 
            "source": "df.createOrReplaceTempView(\"allRows\")", 
            "execution_count": 27, 
            "cell_type": "code", 
            "outputs": []
        }, 
        {
            "metadata": {
                "collapsed": true
            }, 
            "source": "morePlayers = spark.sql(\"\"\"select * from allRows where \n                                            name not in (select name from lowNameCount) and\n                                            position not in (select position from lowPosCount)\"\"\")", 
            "execution_count": 28, 
            "cell_type": "code", 
            "outputs": []
        }, 
        {
            "metadata": {
                "collapsed": true
            }, 
            "source": "#features temp wspd roof surface home stadium_city away_team name position teamid\n#label rushing_yds", 
            "execution_count": 29, 
            "cell_type": "code", 
            "outputs": []
        }, 
        {
            "metadata": {}, 
            "source": "# Create string indexers, one hot encoders, a vector assembler, and the SparkML pipeline", 
            "cell_type": "markdown"
        }, 
        {
            "metadata": {
                "collapsed": true
            }, 
            "source": "from pyspark.ml.feature import StringIndexer\n\nnameInd = StringIndexer(inputCol=\"name\", outputCol=\"nameInd\")\nposInd = StringIndexer(inputCol=\"position\", outputCol=\"posInd\")\n#ampmInd = StringIndexer(inputCol=\"ampm\", outputCol=\"ampmInd\")\nroofInd = StringIndexer(inputCol=\"roof\", outputCol=\"roofInd\")\nsurfInd = StringIndexer(inputCol=\"surface\", outputCol=\"surfInd\")\nstadInd = StringIndexer(inputCol=\"stadium_city\", outputCol=\"stadInd\")\nteamInd = StringIndexer(inputCol=\"teamid\", outputCol=\"teamInd\")\noppInd = StringIndexer(inputCol=\"away_team\", outputCol=\"oppInd\")", 
            "execution_count": 30, 
            "cell_type": "code", 
            "outputs": []
        }, 
        {
            "metadata": {
                "collapsed": true
            }, 
            "source": "from pyspark.ml.feature import OneHotEncoder\n\nnameEnc = OneHotEncoder(inputCol=\"nameInd\", outputCol=\"nameEnc\")\nposEnc = OneHotEncoder(inputCol=\"posInd\", outputCol=\"posEnc\")\n#ampmEnc = OneHotEncoder(inputCol=\"ampmInd\", outputCol=\"ampmEnc\")\nroofEnc = OneHotEncoder(inputCol=\"roofInd\", outputCol=\"roofEnc\")\nsurfEnc = OneHotEncoder(inputCol=\"surfInd\", outputCol=\"surfEnc\")\nstadEnc = OneHotEncoder(inputCol=\"stadInd\", outputCol=\"stadEnc\")\nteamEnc = OneHotEncoder(inputCol=\"teamInd\", outputCol=\"teamEnc\")\noppEnc = OneHotEncoder(inputCol=\"oppInd\", outputCol=\"oppEnc\")", 
            "execution_count": 31, 
            "cell_type": "code", 
            "outputs": []
        }, 
        {
            "metadata": {
                "collapsed": true
            }, 
            "source": "from pyspark.ml.linalg import Vectors\nfrom pyspark.ml.feature import VectorAssembler\n\nvecAss = VectorAssembler(\n    inputCols=[\"nameEnc\", \"posEnc\", \"roofEnc\", \"surfEnc\", \"stadEnc\", \"temp\", \"wspd\", \"ishome\", \"teamEnc\", \"oppEnc\"],\n    outputCol=\"features\")", 
            "execution_count": 32, 
            "cell_type": "code", 
            "outputs": []
        }, 
        {
            "metadata": {
                "collapsed": true
            }, 
            "source": "from pyspark.ml.regression import RandomForestRegressor\n\nrf = RandomForestRegressor(featuresCol=\"features\",labelCol=\"rushing_yds\")", 
            "execution_count": 33, 
            "cell_type": "code", 
            "outputs": []
        }, 
        {
            "metadata": {
                "collapsed": true
            }, 
            "source": "from pyspark.ml import Pipeline\n\npipeline = Pipeline(stages=[nameInd,nameEnc,posInd,posEnc,roofInd,roofEnc,surfInd,surfEnc,\n                           stadInd,stadEnc,teamInd,teamEnc,oppInd,oppEnc,vecAss,rf])", 
            "execution_count": 34, 
            "cell_type": "code", 
            "outputs": []
        }, 
        {
            "metadata": {}, 
            "source": "# Find the best model using a grid search and cross validation", 
            "cell_type": "markdown"
        }, 
        {
            "metadata": {}, 
            "source": "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\nfrom pyspark.ml.evaluation import RegressionEvaluator\nimport datetime\n\nparamGrid = ParamGridBuilder() \\\n    .addGrid(rf.maxBins, [40,60,80])\\\n    .addGrid(rf.maxDepth, [16,20,25])\\\n    .addGrid(rf.numTrees, [80,100,120])\\\n    .build()\n    \nevaluator = RegressionEvaluator(labelCol=\"rushing_yds\", predictionCol=\"prediction\", metricName=\"rmse\")\n\ncrossval = CrossValidator(estimator=pipeline,\n                          estimatorParamMaps=paramGrid,\n                          evaluator=evaluator,\n                          numFolds=5)\n\nprint datetime.datetime.now()\ncvModel = crossval.fit(morePlayers)\nprint datetime.datetime.now()", 
            "execution_count": null, 
            "cell_type": "code", 
            "outputs": [
                {
                    "name": "stdout", 
                    "output_type": "stream", 
                    "text": "2017-09-13 16:27:41.642298\n"
                }
            ]
        }, 
        {
            "metadata": {}, 
            "source": "rmse = evaluator.evaluate(cvModel.bestModel.transform(morePlayers))\nprint(\"Root Mean Squared Error (RMSE) on test data = %g\" % rmse)\n#22.6746", 
            "execution_count": 38, 
            "cell_type": "code", 
            "outputs": [
                {
                    "name": "stdout", 
                    "output_type": "stream", 
                    "text": "Root Mean Squared Error (RMSE) on test data = 22.6746\n"
                }
            ]
        }, 
        {
            "metadata": {
                "scrolled": false
            }, 
            "source": "print cvModel.bestModel.stages[-1]._java_obj.getMaxBins()#<--40\nprint cvModel.bestModel.stages[-1]._java_obj.getMaxDepth()#25-->\nprint cvModel.bestModel.stages[-1]._java_obj.getNumTrees()#120-->", 
            "execution_count": 39, 
            "cell_type": "code", 
            "outputs": [
                {
                    "name": "stdout", 
                    "output_type": "stream", 
                    "text": "40\n25\n120\n"
                }
            ]
        }, 
        {
            "metadata": {
                "collapsed": true
            }, 
            "source": "#features temp wspd roof surface home stadium_city away_team name position teamid\n#label rushing_yds\ndf = df.select('temp','wspd','roof','surface','ishome','stadium_city','away_team','name','position','teamid','rushing_yds')", 
            "execution_count": 40, 
            "cell_type": "code", 
            "outputs": []
        }, 
        {
            "metadata": {}, 
            "source": "# Train the final model on the full dataset", 
            "cell_type": "markdown"
        }, 
        {
            "metadata": {
                "collapsed": true
            }, 
            "source": "from pyspark.ml.regression import RandomForestRegressor\nfrom pyspark.ml import Pipeline\n\nrf = RandomForestRegressor(featuresCol=\"features\",labelCol=\"rushing_yds\",maxBins=60,maxDepth=25,numTrees=80)\npipeline = Pipeline(stages=[nameInd,nameEnc,posInd,posEnc,roofInd,roofEnc,surfInd,surfEnc,\n                           stadInd,stadEnc,teamInd,teamEnc,oppInd,oppEnc,vecAss,rf])\n\nmodel = pipeline.fit(df)", 
            "execution_count": 41, 
            "cell_type": "code", 
            "outputs": []
        }, 
        {
            "metadata": {}, 
            "source": "predictions = model.transform(df)\npredictions.select(\"rushing_yds\",\"prediction\").take(10)", 
            "execution_count": 42, 
            "cell_type": "code", 
            "outputs": [
                {
                    "data": {
                        "text/plain": "[Row(rushing_yds=26, prediction=30.990729166666664),\n Row(rushing_yds=5, prediction=8.366956569974738),\n Row(rushing_yds=5, prediction=6.2899855277760315),\n Row(rushing_yds=47, prediction=32.01399980970929),\n Row(rushing_yds=22, prediction=29.92765865639912),\n Row(rushing_yds=10, prediction=16.792291666666664),\n Row(rushing_yds=-2, prediction=5.651267773709917),\n Row(rushing_yds=44, prediction=33.0953426656544),\n Row(rushing_yds=59, prediction=35.19739571416388),\n Row(rushing_yds=41, prediction=37.45950587606837)]"
                    }, 
                    "metadata": {}, 
                    "execution_count": 42, 
                    "output_type": "execute_result"
                }
            ]
        }, 
        {
            "metadata": {}, 
            "source": "# Save the model to Watson Machine Learning to use as an API", 
            "cell_type": "markdown"
        }, 
        {
            "metadata": {
                "collapsed": true
            }, 
            "source": "# The code was removed by DSX for sharing.", 
            "execution_count": null, 
            "cell_type": "code", 
            "outputs": []
        }, 
        {
            "metadata": {}, 
            "source": "ml_repository_client = MLRepositoryClient(service_path)\nml_repository_client.authorize(username, password)\n\nmodel_artifact = MLRepositoryArtifact(model, training_data=df, name=\"Rush\")\n\nsaved_model = ml_repository_client.models.save(model_artifact)\n\nprint saved_model.meta.available_props()\nprint\nprint \"modelType: \" + saved_model.meta.prop(\"modelType\")\nprint \"trainingDataSchema: \" + str(saved_model.meta.prop(\"trainingDataSchema\"))\nprint \"creationTime: \" + str(saved_model.meta.prop(\"creationTime\"))\nprint \"modelVersionHref: \" + saved_model.meta.prop(\"modelVersionHref\")\nprint \"label: \" + saved_model.meta.prop(\"label\")", 
            "execution_count": 43, 
            "cell_type": "code", 
            "outputs": [
                {
                    "name": "stdout", 
                    "output_type": "stream", 
                    "text": "['inputDataSchema', 'evaluationMetrics', 'pipelineVersionHref', 'modelVersionHref', 'trainingDataRef', 'pipelineType', 'creationTime', 'lastUpdated', 'label', 'authorEmail', 'trainingDataSchema', 'authorName', 'version', 'modelType', 'runtime', 'evaluationMethod']\n\nmodelType: sparkml-model-2.0\ntrainingDataSchema: {u'fields': [{u'nullable': True, u'type': u'integer', u'name': u'temp', u'metadata': {}}, {u'nullable': True, u'type': u'integer', u'name': u'wspd', u'metadata': {}}, {u'nullable': True, u'type': u'string', u'name': u'roof', u'metadata': {}}, {u'nullable': True, u'type': u'string', u'name': u'surface', u'metadata': {}}, {u'nullable': True, u'type': u'integer', u'name': u'ishome', u'metadata': {}}, {u'nullable': True, u'type': u'string', u'name': u'stadium_city', u'metadata': {}}, {u'nullable': True, u'type': u'string', u'name': u'away_team', u'metadata': {}}, {u'nullable': True, u'type': u'string', u'name': u'name', u'metadata': {}}, {u'nullable': True, u'type': u'string', u'name': u'position', u'metadata': {}}, {u'nullable': True, u'type': u'string', u'name': u'teamid', u'metadata': {}}, {u'nullable': True, u'type': u'integer', u'name': u'rushing_yds', u'metadata': {}}], u'type': u'struct'}\ncreationTime: 2017-09-14 01:00:31.235000+00:00\nmodelVersionHref: https://ibm-watson-ml.mybluemix.net/v2/artifacts/models/7d18e7a5-3d13-4122-bc67-0e6e7404feb0/versions/849b752e-7fee-4dab-8aaf-0d30bc6774c7\nlabel: rushing_yds\n"
                }
            ]
        }, 
        {
            "metadata": {}, 
            "source": "loadedModelArtifact = ml_repository_client.models.get(saved_model.uid)\n\nprint str(loadedModelArtifact.name)", 
            "execution_count": 44, 
            "cell_type": "code", 
            "outputs": [
                {
                    "name": "stdout", 
                    "output_type": "stream", 
                    "text": "Rush\n"
                }
            ]
        }, 
        {
            "metadata": {
                "collapsed": true
            }, 
            "source": "", 
            "execution_count": null, 
            "cell_type": "code", 
            "outputs": []
        }
    ], 
    "nbformat_minor": 1
}