{
    "metadata": {
        "language_info": {
            "file_extension": ".py", 
            "name": "python", 
            "mimetype": "text/x-python", 
            "nbconvert_exporter": "python", 
            "version": "2.7.11", 
            "codemirror_mode": {
                "name": "ipython", 
                "version": 2
            }, 
            "pygments_lexer": "ipython2"
        }, 
        "kernelspec": {
            "display_name": "Python 2 with Spark 2.1", 
            "name": "python2-spark21", 
            "language": "python"
        }
    }, 
    "nbformat": 4, 
    "cells": [
        {
            "metadata": {}, 
            "source": "# Load the clean NFL data", 
            "cell_type": "markdown"
        }, 
        {
            "metadata": {
                "collapsed": true
            }, 
            "source": "# The code was removed by DSX for sharing.", 
            "execution_count": 1, 
            "cell_type": "code", 
            "outputs": []
        }, 
        {
            "metadata": {}, 
            "source": "configuration_name = 'os_f02c10e2d3544fe3ae82e368ee5170ef_configs'\nbmos = ibmos2spark.bluemix(sc, credentials, configuration_name)\n\ndf = spark.read\\\n  .format('org.apache.spark.sql.execution.datasources.csv.CSVFileFormat')\\\n  .option('header', 'true').option('inferschema','true')\\\n  .load(bmos.url('HWNFLDemo', 'rb_all_joined_filter.csv'))", 
            "execution_count": 2, 
            "cell_type": "code", 
            "outputs": []
        }, 
        {
            "metadata": {}, 
            "source": "df.take(5)", 
            "execution_count": 3, 
            "cell_type": "code", 
            "outputs": [
                {
                    "data": {
                        "text/plain": "[Row(_c0=0, name=u'C.Newton', teamid=u'CAR', home_team=u'CAR', away_team=u'GB', rushing_tds=1, receiving_yds=0, position=u'QB', rushing_yds=57, home=True, opponent=u'GB', stadium_city=u'Charlotte, NC', capacity=75419, surface=u'Voyager Bermuda Grass', roof=u'Open', temp=55, wspd=9, vis=10, pressure=30, dewPt=34.0, precip_total=None, hi=55.0),\n Row(_c0=1, name=u'J.Stewart', teamid=u'CAR', home_team=u'CAR', away_team=u'GB', rushing_tds=0, receiving_yds=2, position=u'RB', rushing_yds=66, home=True, opponent=u'GB', stadium_city=u'Charlotte, NC', capacity=75419, surface=u'Voyager Bermuda Grass', roof=u'Open', temp=55, wspd=9, vis=10, pressure=30, dewPt=34.0, precip_total=None, hi=55.0),\n Row(_c0=2, name=u'C.Brown', teamid=u'CAR', home_team=u'CAR', away_team=u'GB', rushing_tds=0, receiving_yds=50, position=u'WR', rushing_yds=-12, home=True, opponent=u'GB', stadium_city=u'Charlotte, NC', capacity=75419, surface=u'Voyager Bermuda Grass', roof=u'Open', temp=55, wspd=9, vis=10, pressure=30, dewPt=34.0, precip_total=None, hi=55.0),\n Row(_c0=3, name=u'F.Whittaker', teamid=u'CAR', home_team=u'CAR', away_team=u'GB', rushing_tds=0, receiving_yds=0, position=u'RB', rushing_yds=13, home=True, opponent=u'GB', stadium_city=u'Charlotte, NC', capacity=75419, surface=u'Voyager Bermuda Grass', roof=u'Open', temp=55, wspd=9, vis=10, pressure=30, dewPt=34.0, precip_total=None, hi=55.0),\n Row(_c0=4, name=u'M.Tolbert', teamid=u'CAR', home_team=u'CAR', away_team=u'GB', rushing_tds=0, receiving_yds=0, position=u'FB', rushing_yds=7, home=True, opponent=u'GB', stadium_city=u'Charlotte, NC', capacity=75419, surface=u'Voyager Bermuda Grass', roof=u'Open', temp=55, wspd=9, vis=10, pressure=30, dewPt=34.0, precip_total=None, hi=55.0)]"
                    }, 
                    "metadata": {}, 
                    "execution_count": 3, 
                    "output_type": "execute_result"
                }
            ]
        }, 
        {
            "metadata": {}, 
            "source": "df.count()", 
            "execution_count": 4, 
            "cell_type": "code", 
            "outputs": [
                {
                    "data": {
                        "text/plain": "3235"
                    }, 
                    "metadata": {}, 
                    "execution_count": 4, 
                    "output_type": "execute_result"
                }
            ]
        }, 
        {
            "metadata": {}, 
            "source": "# Remove null rows and rows with values that don't appear enough for training", 
            "cell_type": "markdown"
        }, 
        {
            "metadata": {
                "collapsed": true
            }, 
            "source": "df = df.where(\"not temp is Null\")", 
            "execution_count": 5, 
            "cell_type": "code", 
            "outputs": []
        }, 
        {
            "metadata": {
                "collapsed": true
            }, 
            "source": "df = df.withColumn('ishome', df['home'].cast('integer'))", 
            "execution_count": 6, 
            "cell_type": "code", 
            "outputs": []
        }, 
        {
            "metadata": {
                "collapsed": true
            }, 
            "source": "df.groupBy(\"position\").count().where('count < 10').createOrReplaceTempView(\"lowPosCount\")", 
            "execution_count": 7, 
            "cell_type": "code", 
            "outputs": []
        }, 
        {
            "metadata": {
                "collapsed": true
            }, 
            "source": "df.groupBy(\"name\").count().where('count < 10').createOrReplaceTempView(\"lowNameCount\")", 
            "execution_count": 8, 
            "cell_type": "code", 
            "outputs": []
        }, 
        {
            "metadata": {
                "collapsed": true
            }, 
            "source": "df.createOrReplaceTempView(\"allRows\")", 
            "execution_count": 9, 
            "cell_type": "code", 
            "outputs": []
        }, 
        {
            "metadata": {
                "collapsed": true
            }, 
            "source": "morePlayers = spark.sql(\"\"\"select * from allRows where \n                                            name not in (select name from lowNameCount) and\n                                            position not in (select position from lowPosCount)\"\"\")", 
            "execution_count": 10, 
            "cell_type": "code", 
            "outputs": []
        }, 
        {
            "metadata": {
                "collapsed": true
            }, 
            "source": "#features temp wspd roof surface home stadium_city away_team name position teamid\n#label rushing_yds", 
            "execution_count": 11, 
            "cell_type": "code", 
            "outputs": []
        }, 
        {
            "metadata": {}, 
            "source": "# Create string indexers, one hot encoders, a vector assembler, and the SparkML pipeline", 
            "cell_type": "markdown"
        }, 
        {
            "metadata": {
                "collapsed": true
            }, 
            "source": "from pyspark.ml.feature import StringIndexer\n\nnameInd = StringIndexer(inputCol=\"name\", outputCol=\"nameInd\")\nposInd = StringIndexer(inputCol=\"position\", outputCol=\"posInd\")\n#ampmInd = StringIndexer(inputCol=\"ampm\", outputCol=\"ampmInd\")\nroofInd = StringIndexer(inputCol=\"roof\", outputCol=\"roofInd\")\nsurfInd = StringIndexer(inputCol=\"surface\", outputCol=\"surfInd\")\nstadInd = StringIndexer(inputCol=\"stadium_city\", outputCol=\"stadInd\")\nteamInd = StringIndexer(inputCol=\"teamid\", outputCol=\"teamInd\")\noppInd = StringIndexer(inputCol=\"away_team\", outputCol=\"oppInd\")", 
            "execution_count": 12, 
            "cell_type": "code", 
            "outputs": []
        }, 
        {
            "metadata": {
                "collapsed": true
            }, 
            "source": "from pyspark.ml.feature import OneHotEncoder\n\nnameEnc = OneHotEncoder(inputCol=\"nameInd\", outputCol=\"nameEnc\")\nposEnc = OneHotEncoder(inputCol=\"posInd\", outputCol=\"posEnc\")\n#ampmEnc = OneHotEncoder(inputCol=\"ampmInd\", outputCol=\"ampmEnc\")\nroofEnc = OneHotEncoder(inputCol=\"roofInd\", outputCol=\"roofEnc\")\nsurfEnc = OneHotEncoder(inputCol=\"surfInd\", outputCol=\"surfEnc\")\nstadEnc = OneHotEncoder(inputCol=\"stadInd\", outputCol=\"stadEnc\")\nteamEnc = OneHotEncoder(inputCol=\"teamInd\", outputCol=\"teamEnc\")\noppEnc = OneHotEncoder(inputCol=\"oppInd\", outputCol=\"oppEnc\")", 
            "execution_count": 13, 
            "cell_type": "code", 
            "outputs": []
        }, 
        {
            "metadata": {
                "collapsed": true
            }, 
            "source": "from pyspark.ml.linalg import Vectors\nfrom pyspark.ml.feature import VectorAssembler\n\nvecAss = VectorAssembler(\n    inputCols=[\"nameEnc\", \"posEnc\", \"roofEnc\", \"surfEnc\", \"stadEnc\", \"temp\", \"wspd\", \"ishome\", \"teamEnc\", \"oppEnc\"],\n    outputCol=\"features\")", 
            "execution_count": 14, 
            "cell_type": "code", 
            "outputs": []
        }, 
        {
            "metadata": {
                "collapsed": true
            }, 
            "source": "from pyspark.ml.regression import RandomForestRegressor\n\nrf = RandomForestRegressor(featuresCol=\"features\",labelCol=\"rushing_yds\")", 
            "execution_count": 15, 
            "cell_type": "code", 
            "outputs": []
        }, 
        {
            "metadata": {
                "collapsed": true
            }, 
            "source": "from pyspark.ml import Pipeline\n\npipeline = Pipeline(stages=[nameInd,nameEnc,posInd,posEnc,roofInd,roofEnc,surfInd,surfEnc,\n                           stadInd,stadEnc,teamInd,teamEnc,oppInd,oppEnc,vecAss,rf])", 
            "execution_count": 16, 
            "cell_type": "code", 
            "outputs": []
        }, 
        {
            "metadata": {}, 
            "source": "# Find the best model using a grid search and cross validation", 
            "cell_type": "markdown"
        }, 
        {
            "metadata": {}, 
            "source": "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\nfrom pyspark.ml.evaluation import RegressionEvaluator\nimport datetime\n\nparamGrid = ParamGridBuilder() \\\n    .addGrid(rf.maxBins, [40,60,80])\\\n    .addGrid(rf.maxDepth, [16,20,25])\\\n    .addGrid(rf.numTrees, [80,100,120])\\\n    .build()\n    \nevaluator = RegressionEvaluator(labelCol=\"rushing_yds\", predictionCol=\"prediction\", metricName=\"rmse\")\n\ncrossval = CrossValidator(estimator=pipeline,\n                          estimatorParamMaps=paramGrid,\n                          evaluator=evaluator,\n                          numFolds=5)\n\nprint datetime.datetime.now()\ncvModel = crossval.fit(morePlayers)\nprint datetime.datetime.now()", 
            "execution_count": null, 
            "cell_type": "code", 
            "outputs": [
                {
                    "name": "stdout", 
                    "output_type": "stream", 
                    "text": "2017-09-13 16:27:41.642298\n"
                }
            ]
        }, 
        {
            "metadata": {}, 
            "source": "rmse = evaluator.evaluate(cvModel.bestModel.transform(morePlayers))\nprint(\"Root Mean Squared Error (RMSE) on test data = %g\" % rmse)\n#22.6746", 
            "execution_count": 38, 
            "cell_type": "code", 
            "outputs": [
                {
                    "name": "stdout", 
                    "output_type": "stream", 
                    "text": "Root Mean Squared Error (RMSE) on test data = 22.6746\n"
                }
            ]
        }, 
        {
            "metadata": {
                "scrolled": false
            }, 
            "source": "print cvModel.bestModel.stages[-1]._java_obj.getMaxBins()#<--40\nprint cvModel.bestModel.stages[-1]._java_obj.getMaxDepth()#25-->\nprint cvModel.bestModel.stages[-1]._java_obj.getNumTrees()#120-->", 
            "execution_count": 39, 
            "cell_type": "code", 
            "outputs": [
                {
                    "name": "stdout", 
                    "output_type": "stream", 
                    "text": "40\n25\n120\n"
                }
            ]
        }, 
        {
            "metadata": {}, 
            "source": "#features temp wspd roof surface home stadium_city away_team name position teamid\n#label rushing_yds\ndf = df.select('temp','wspd','roof','surface','ishome','stadium_city','away_team','name','position','teamid','rushing_yds')", 
            "execution_count": 17, 
            "cell_type": "code", 
            "outputs": []
        }, 
        {
            "metadata": {}, 
            "source": "# Train the final model on the full dataset", 
            "cell_type": "markdown"
        }, 
        {
            "metadata": {
                "collapsed": true
            }, 
            "source": "from pyspark.ml.regression import RandomForestRegressor\nfrom pyspark.ml import Pipeline\n\nrf = RandomForestRegressor(featuresCol=\"features\",labelCol=\"rushing_yds\",maxBins=60,maxDepth=25,numTrees=80)\npipeline = Pipeline(stages=[nameInd,nameEnc,posInd,posEnc,roofInd,roofEnc,surfInd,surfEnc,\n                           stadInd,stadEnc,teamInd,teamEnc,oppInd,oppEnc,vecAss,rf])\n\nmodel = pipeline.fit(df)", 
            "execution_count": 18, 
            "cell_type": "code", 
            "outputs": []
        }, 
        {
            "metadata": {}, 
            "source": "predictions = model.transform(df)\npredictions.select(\"rushing_yds\",\"prediction\").take(10)", 
            "execution_count": 19, 
            "cell_type": "code", 
            "outputs": [
                {
                    "data": {
                        "text/plain": "[Row(rushing_yds=57, prediction=43.25188446969697),\n Row(rushing_yds=66, prediction=55.91193992269981),\n Row(rushing_yds=-12, prediction=-0.47230873162981346),\n Row(rushing_yds=13, prediction=29.221363726261092),\n Row(rushing_yds=7, prediction=9.154160358837071),\n Row(rushing_yds=-1, prediction=8.541197843513272),\n Row(rushing_yds=43, prediction=36.063541666666666),\n Row(rushing_yds=95, prediction=65.39484666873156),\n Row(rushing_yds=2, prediction=6.137683377002537),\n Row(rushing_yds=1, prediction=28.185232278673737)]"
                    }, 
                    "metadata": {}, 
                    "execution_count": 19, 
                    "output_type": "execute_result"
                }
            ]
        }, 
        {
            "metadata": {}, 
            "source": "# Save the model to Watson Machine Learning to use as an API", 
            "cell_type": "markdown"
        }, 
        {
            "metadata": {
                "collapsed": true
            }, 
            "source": "# The code was removed by DSX for sharing.", 
            "execution_count": 20, 
            "cell_type": "code", 
            "outputs": []
        }, 
        {
            "metadata": {}, 
            "source": "ml_repository_client = MLRepositoryClient(service_path)\nml_repository_client.authorize(username, password)\n\nmodel_artifact = MLRepositoryArtifact(model, training_data=df, name=\"Rush\")\n\nsaved_model = ml_repository_client.models.save(model_artifact)\n\nprint saved_model.meta.available_props()\nprint\nprint \"modelType: \" + saved_model.meta.prop(\"modelType\")\nprint \"trainingDataSchema: \" + str(saved_model.meta.prop(\"trainingDataSchema\"))\nprint \"creationTime: \" + str(saved_model.meta.prop(\"creationTime\"))\nprint \"modelVersionHref: \" + saved_model.meta.prop(\"modelVersionHref\")\nprint \"label: \" + saved_model.meta.prop(\"label\")", 
            "execution_count": 23, 
            "cell_type": "code", 
            "outputs": [
                {
                    "name": "stdout", 
                    "output_type": "stream", 
                    "text": "['inputDataSchema', 'evaluationMetrics', 'pipelineVersionHref', 'modelVersionHref', 'trainingDataRef', 'pipelineType', 'creationTime', 'lastUpdated', 'label', 'authorEmail', 'trainingDataSchema', 'authorName', 'version', 'modelType', 'runtime', 'evaluationMethod']\n\nmodelType: sparkml-model-2.1\ntrainingDataSchema: {u'fields': [{u'nullable': True, u'type': u'integer', u'name': u'temp', u'metadata': {}}, {u'nullable': True, u'type': u'integer', u'name': u'wspd', u'metadata': {}}, {u'nullable': True, u'type': u'string', u'name': u'roof', u'metadata': {}}, {u'nullable': True, u'type': u'string', u'name': u'surface', u'metadata': {}}, {u'nullable': True, u'type': u'integer', u'name': u'ishome', u'metadata': {}}, {u'nullable': True, u'type': u'string', u'name': u'stadium_city', u'metadata': {}}, {u'nullable': True, u'type': u'string', u'name': u'away_team', u'metadata': {}}, {u'nullable': True, u'type': u'string', u'name': u'name', u'metadata': {}}, {u'nullable': True, u'type': u'string', u'name': u'position', u'metadata': {}}, {u'nullable': True, u'type': u'string', u'name': u'teamid', u'metadata': {}}, {u'nullable': True, u'type': u'integer', u'name': u'rushing_yds', u'metadata': {}}], u'type': u'struct'}\ncreationTime: 2017-10-18 18:10:23.776000+00:00\nmodelVersionHref: https://ibm-watson-ml.mybluemix.net/v2/artifacts/models/e8225475-6eb1-42d1-a268-b5684bbd7841/versions/26c52b07-27f8-47d9-9559-e67cf0be7300\nlabel: rushing_yds\n"
                }
            ]
        }, 
        {
            "metadata": {}, 
            "source": "loadedModelArtifact = ml_repository_client.models.get(saved_model.uid)\n\nprint str(loadedModelArtifact.name)", 
            "execution_count": 24, 
            "cell_type": "code", 
            "outputs": [
                {
                    "name": "stdout", 
                    "output_type": "stream", 
                    "text": "Rush\n"
                }
            ]
        }, 
        {
            "metadata": {
                "collapsed": true
            }, 
            "source": "", 
            "execution_count": null, 
            "cell_type": "code", 
            "outputs": []
        }
    ], 
    "nbformat_minor": 1
}